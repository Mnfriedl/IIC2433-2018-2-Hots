{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  *Neuronal Network* para determinar ganador de partida en *Heroes of the Storm*\n",
    "- Autores: Maximiliano Friedl y Felipe Gómez\n",
    "- IIC2433 Minería de datos 2018-2\n",
    "- Entrega 2\n",
    "- Fecha de entrega: 6 de diciembre de 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Descripción de la red neuronal\n",
    "### 1.1. Capa de entrada\n",
    "La entrada a al red neuronal será un vector creado a partir del preprocesamiento de la base de datos. la entrada corresponde a un vector con 350 datos. La descripción del vector de entrada se encuentra en otro archivo.\n",
    "\n",
    "Esto es lo que se le pasará a la primera capa intermedia y a partir de allí, se calcularán cada uno de los pesos necesarios para otorgar la salida correcta en el formato de salida.\n",
    "### 1.2. Capas intermedias\n",
    "No se sabe a priori cuántas capas intermedias poner ni cuántas neuronas debería tener. Se harán varias pruebas para saber qué debería ir aquí (se elegirá de acuerdo a la que pueda predecir mejor el resultado de una partida.\n",
    "### 1.3. Capa de salida\n",
    "Se creará una red neuronal dos neuronas en nuestra capa de salida, donde cada una representará qué equipo será el ganador. Se utilizará una capa *Softmax*, que ayudará a que cada neurona de salida exprese una probabilidad de victoria de ese equipo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (35518, 350)\n",
      "X_test: (17495, 350)\n",
      "y_train: (35518,)\n",
      "y_test: (17495,)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.load('dataset.npy')\n",
    "y = np.load('classifications.npy')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_train:',y_train.shape)\n",
    "print('y_test:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 1: 4 capas, 100 épocas de entrenamiento, pérdida con función *binary_crossentropy*, Adam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35518/35518 [==============================] - 4s 105us/step - loss: 0.6933 - acc: 0.5070\n",
      "Epoch 2/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.6916 - acc: 0.5194\n",
      "Epoch 3/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.6865 - acc: 0.5389\n",
      "Epoch 4/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.6781 - acc: 0.5592\n",
      "Epoch 5/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.6673 - acc: 0.5785\n",
      "Epoch 6/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.6565 - acc: 0.5953\n",
      "Epoch 7/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.6469 - acc: 0.6083\n",
      "Epoch 8/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.6387 - acc: 0.6201\n",
      "Epoch 9/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.6309 - acc: 0.6291\n",
      "Epoch 10/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.6244 - acc: 0.6348\n",
      "Epoch 11/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.6184 - acc: 0.6423\n",
      "Epoch 12/100\n",
      "35518/35518 [==============================] - 4s 103us/step - loss: 0.6127 - acc: 0.6468\n",
      "Epoch 13/100\n",
      "35518/35518 [==============================] - 3s 91us/step - loss: 0.6075 - acc: 0.6530\n",
      "Epoch 14/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.6030 - acc: 0.6570\n",
      "Epoch 15/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.5978 - acc: 0.6604\n",
      "Epoch 16/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.5927 - acc: 0.6666\n",
      "Epoch 17/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.5885 - acc: 0.6692\n",
      "Epoch 18/100\n",
      "35518/35518 [==============================] - 3s 95us/step - loss: 0.5848 - acc: 0.6725\n",
      "Epoch 19/100\n",
      "35518/35518 [==============================] - 3s 95us/step - loss: 0.5810 - acc: 0.6761\n",
      "Epoch 20/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.5783 - acc: 0.6821\n",
      "Epoch 21/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.5738 - acc: 0.6828\n",
      "Epoch 22/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.5719 - acc: 0.6842\n",
      "Epoch 23/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.5691 - acc: 0.6847\n",
      "Epoch 24/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.5666 - acc: 0.6889\n",
      "Epoch 25/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.5638 - acc: 0.6898\n",
      "Epoch 26/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.5605 - acc: 0.6921\n",
      "Epoch 27/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.5580 - acc: 0.6926\n",
      "Epoch 28/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.5572 - acc: 0.6949\n",
      "Epoch 29/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.5543 - acc: 0.6967\n",
      "Epoch 30/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.5519 - acc: 0.6978\n",
      "Epoch 31/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.5493 - acc: 0.7014\n",
      "Epoch 32/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.5488 - acc: 0.7009\n",
      "Epoch 33/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.5471 - acc: 0.7031\n",
      "Epoch 34/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.5440 - acc: 0.7053\n",
      "Epoch 35/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.5418 - acc: 0.7044\n",
      "Epoch 36/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.5415 - acc: 0.7053\n",
      "Epoch 37/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.5399 - acc: 0.7072\n",
      "Epoch 38/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.5376 - acc: 0.7077\n",
      "Epoch 39/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.5366 - acc: 0.7094\n",
      "Epoch 40/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.5340 - acc: 0.7105\n",
      "Epoch 41/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.5334 - acc: 0.7114\n",
      "Epoch 42/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.5329 - acc: 0.7124\n",
      "Epoch 43/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.5306 - acc: 0.7124\n",
      "Epoch 44/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.5298 - acc: 0.7122\n",
      "Epoch 45/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.5274 - acc: 0.7172\n",
      "Epoch 46/100\n",
      "35518/35518 [==============================] - 3s 97us/step - loss: 0.5274 - acc: 0.7163\n",
      "Epoch 47/100\n",
      "35518/35518 [==============================] - 4s 111us/step - loss: 0.5257 - acc: 0.7162\n",
      "Epoch 48/100\n",
      "35518/35518 [==============================] - 4s 116us/step - loss: 0.5236 - acc: 0.7185\n",
      "Epoch 49/100\n",
      "35518/35518 [==============================] - 4s 119us/step - loss: 0.5228 - acc: 0.7202\n",
      "Epoch 50/100\n",
      "35518/35518 [==============================] - 5s 153us/step - loss: 0.5222 - acc: 0.7195\n",
      "Epoch 51/100\n",
      "35518/35518 [==============================] - 6s 178us/step - loss: 0.5218 - acc: 0.7205\n",
      "Epoch 52/100\n",
      "35518/35518 [==============================] - 8s 226us/step - loss: 0.5198 - acc: 0.7223\n",
      "Epoch 53/100\n",
      "35518/35518 [==============================] - 9s 265us/step - loss: 0.5198 - acc: 0.7201\n",
      "Epoch 54/100\n",
      "35518/35518 [==============================] - 11s 320us/step - loss: 0.5186 - acc: 0.7228\n",
      "Epoch 55/100\n",
      "35518/35518 [==============================] - 6s 182us/step - loss: 0.5169 - acc: 0.7215\n",
      "Epoch 56/100\n",
      "35518/35518 [==============================] - 6s 161us/step - loss: 0.5161 - acc: 0.7243\n",
      "Epoch 57/100\n",
      "35518/35518 [==============================] - 4s 123us/step - loss: 0.5167 - acc: 0.7218\n",
      "Epoch 58/100\n",
      "35518/35518 [==============================] - 5s 129us/step - loss: 0.5153 - acc: 0.7244\n",
      "Epoch 59/100\n",
      "35518/35518 [==============================] - 7s 194us/step - loss: 0.5131 - acc: 0.7266\n",
      "Epoch 60/100\n",
      "35518/35518 [==============================] - 7s 186us/step - loss: 0.5138 - acc: 0.7258\n",
      "Epoch 61/100\n",
      "35518/35518 [==============================] - 5s 128us/step - loss: 0.5116 - acc: 0.7270\n",
      "Epoch 62/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.5100 - acc: 0.7284\n",
      "Epoch 63/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.5090 - acc: 0.7288\n",
      "Epoch 64/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.5085 - acc: 0.7285\n",
      "Epoch 65/100\n",
      "35518/35518 [==============================] - 4s 123us/step - loss: 0.5086 - acc: 0.7272\n",
      "Epoch 66/100\n",
      "35518/35518 [==============================] - 4s 114us/step - loss: 0.5070 - acc: 0.7288\n",
      "Epoch 67/100\n",
      "35518/35518 [==============================] - 6s 168us/step - loss: 0.5062 - acc: 0.7291\n",
      "Epoch 68/100\n",
      "35518/35518 [==============================] - 15s 411us/step - loss: 0.5071 - acc: 0.7279\n",
      "Epoch 69/100\n",
      "35518/35518 [==============================] - 17s 465us/step - loss: 0.5063 - acc: 0.7288\n",
      "Epoch 70/100\n",
      "35518/35518 [==============================] - 9s 264us/step - loss: 0.5053 - acc: 0.7292\n",
      "Epoch 71/100\n",
      "35518/35518 [==============================] - 7s 202us/step - loss: 0.5033 - acc: 0.7300\n",
      "Epoch 72/100\n",
      "35518/35518 [==============================] - 7s 204us/step - loss: 0.5027 - acc: 0.7302\n",
      "Epoch 73/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.5052 - acc: 0.7288\n",
      "Epoch 74/100\n",
      "35518/35518 [==============================] - 3s 95us/step - loss: 0.5023 - acc: 0.7300\n",
      "Epoch 75/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.5009 - acc: 0.7314\n",
      "Epoch 76/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.5003 - acc: 0.7326\n",
      "Epoch 77/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.4994 - acc: 0.7321\n",
      "Epoch 78/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.5002 - acc: 0.7324\n",
      "Epoch 79/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.4984 - acc: 0.7336\n",
      "Epoch 80/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.4992 - acc: 0.7340\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.4978 - acc: 0.7348\n",
      "Epoch 82/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.4963 - acc: 0.7333\n",
      "Epoch 83/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.4970 - acc: 0.7350\n",
      "Epoch 84/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.4959 - acc: 0.7359\n",
      "Epoch 85/100\n",
      "35518/35518 [==============================] - 3s 76us/step - loss: 0.4951 - acc: 0.7368\n",
      "Epoch 86/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.4944 - acc: 0.7351\n",
      "Epoch 87/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.4947 - acc: 0.7341\n",
      "Epoch 88/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.4944 - acc: 0.7353\n",
      "Epoch 89/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.4939 - acc: 0.7369\n",
      "Epoch 90/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.4956 - acc: 0.7367\n",
      "Epoch 91/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.4914 - acc: 0.7384\n",
      "Epoch 92/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.4908 - acc: 0.7390\n",
      "Epoch 93/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.4912 - acc: 0.7385\n",
      "Epoch 94/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.4916 - acc: 0.7375\n",
      "Epoch 95/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.4908 - acc: 0.7396\n",
      "Epoch 96/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.4878 - acc: 0.7409\n",
      "Epoch 97/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.4901 - acc: 0.7402\n",
      "Epoch 98/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.4885 - acc: 0.7399\n",
      "Epoch 99/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.4881 - acc: 0.7403\n",
      "Epoch 100/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.4879 - acc: 0.7397\n",
      "17495/17495 [==============================] - 1s 29us/step\n",
      "TEST: \n",
      "\n",
      "acc: 49.50%\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(16, input_dim=X.shape[1], activation='relu'))\n",
    "model_1.add(Dense(8, input_dim=16, activation='relu'))\n",
    "model_1.add(Dense(8, input_dim=8, activation='relu'))\n",
    "model_1.add(Dense(1, input_dim=8, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_1.fit(X_train, y_train, epochs=100, batch_size=15)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model_1.evaluate(X_test, y_test)\n",
    "print('TEST: ')\n",
    "print(\"\\n%s: %.2f%%\" % (model_1.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model_1.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 2: 8 capas, 100 épocas de entrenamiento, pérdida con función *binary_crossentropy*, Adam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35518/35518 [==============================] - 6s 181us/step - loss: 0.6931 - acc: 0.5077\n",
      "Epoch 2/100\n",
      "35518/35518 [==============================] - 6s 163us/step - loss: 0.6930 - acc: 0.5081\n",
      "Epoch 3/100\n",
      "35518/35518 [==============================] - 6s 165us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 4/100\n",
      "35518/35518 [==============================] - 6s 171us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 5/100\n",
      "35518/35518 [==============================] - 6s 162us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 6/100\n",
      "35518/35518 [==============================] - 6s 155us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 7/100\n",
      "35518/35518 [==============================] - 6s 158us/step - loss: 0.6931 - acc: 0.5080\n",
      "Epoch 8/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 9/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 10/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.6931 - acc: 0.5082\n",
      "Epoch 11/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 12/100\n",
      "35518/35518 [==============================] - 6s 158us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 13/100\n",
      "35518/35518 [==============================] - 6s 158us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 14/100\n",
      "35518/35518 [==============================] - 5s 153us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 15/100\n",
      "35518/35518 [==============================] - 6s 159us/step - loss: 0.6931 - acc: 0.5081\n",
      "Epoch 16/100\n",
      "35518/35518 [==============================] - 5s 155us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 17/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6930 - acc: 0.5064\n",
      "Epoch 18/100\n",
      "35518/35518 [==============================] - 5s 138us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 19/100\n",
      "35518/35518 [==============================] - 5s 152us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 20/100\n",
      "35518/35518 [==============================] - 6s 175us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 21/100\n",
      "35518/35518 [==============================] - 6s 167us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 22/100\n",
      "35518/35518 [==============================] - 6s 165us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 23/100\n",
      "35518/35518 [==============================] - 6s 164us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 24/100\n",
      "35518/35518 [==============================] - 6s 155us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 25/100\n",
      "35518/35518 [==============================] - 6s 166us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 26/100\n",
      "35518/35518 [==============================] - 6s 162us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 27/100\n",
      "35518/35518 [==============================] - 6s 162us/step - loss: 0.6931 - acc: 0.5073\n",
      "Epoch 28/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 29/100\n",
      "35518/35518 [==============================] - 6s 155us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 30/100\n",
      "35518/35518 [==============================] - 6s 159us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 31/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.6931 - acc: 0.5081\n",
      "Epoch 32/100\n",
      "35518/35518 [==============================] - 5s 151us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 33/100\n",
      "35518/35518 [==============================] - 5s 150us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 34/100\n",
      "35518/35518 [==============================] - 5s 149us/step - loss: 0.6931 - acc: 0.5081\n",
      "Epoch 35/100\n",
      "35518/35518 [==============================] - 5s 151us/step - loss: 0.6931 - acc: 0.5077\n",
      "Epoch 36/100\n",
      "35518/35518 [==============================] - 5s 148us/step - loss: 0.6930 - acc: 0.5079\n",
      "Epoch 37/100\n",
      "35518/35518 [==============================] - 5s 149us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 38/100\n",
      "35518/35518 [==============================] - 5s 149us/step - loss: 0.6931 - acc: 0.5081\n",
      "Epoch 39/100\n",
      "35518/35518 [==============================] - 5s 149us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 40/100\n",
      "35518/35518 [==============================] - 5s 149us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 41/100\n",
      "35518/35518 [==============================] - 5s 150us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 42/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 43/100\n",
      "35518/35518 [==============================] - 5s 148us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 44/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6930 - acc: 0.5082\n",
      "Epoch 45/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6930 - acc: 0.5082\n",
      "Epoch 46/100\n",
      "35518/35518 [==============================] - 5s 150us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 47/100\n",
      "35518/35518 [==============================] - 5s 149us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 48/100\n",
      "35518/35518 [==============================] - 5s 152us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 49/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6930 - acc: 0.5077\n",
      "Epoch 50/100\n",
      "35518/35518 [==============================] - 5s 149us/step - loss: 0.6931 - acc: 0.5081\n",
      "Epoch 51/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 52/100\n",
      "35518/35518 [==============================] - 5s 151us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 53/100\n",
      "35518/35518 [==============================] - 5s 146us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 54/100\n",
      "35518/35518 [==============================] - 5s 148us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 55/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 56/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 57/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.6930 - acc: 0.5084\n",
      "Epoch 58/100\n",
      "35518/35518 [==============================] - 7s 185us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 59/100\n",
      "35518/35518 [==============================] - 6s 178us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 60/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.6930 - acc: 0.5065\n",
      "Epoch 61/100\n",
      "35518/35518 [==============================] - 6s 159us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 62/100\n",
      "35518/35518 [==============================] - 6s 159us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 63/100\n",
      "35518/35518 [==============================] - 5s 152us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 64/100\n",
      "35518/35518 [==============================] - 5s 143us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 65/100\n",
      "35518/35518 [==============================] - 5s 146us/step - loss: 0.6930 - acc: 0.5078\n",
      "Epoch 66/100\n",
      "35518/35518 [==============================] - 5s 143us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 67/100\n",
      "35518/35518 [==============================] - 5s 143us/step - loss: 0.6931 - acc: 0.5076\n",
      "Epoch 68/100\n",
      "35518/35518 [==============================] - 5s 141us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 69/100\n",
      "35518/35518 [==============================] - 5s 143us/step - loss: 0.6931 - acc: 0.5077\n",
      "Epoch 70/100\n",
      "35518/35518 [==============================] - 5s 144us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 71/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 72/100\n",
      "35518/35518 [==============================] - 6s 168us/step - loss: 0.6931 - acc: 0.5081\n",
      "Epoch 73/100\n",
      "35518/35518 [==============================] - 6s 167us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 74/100\n",
      "35518/35518 [==============================] - 6s 161us/step - loss: 0.6930 - acc: 0.5075\n",
      "Epoch 75/100\n",
      "35518/35518 [==============================] - 5s 148us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 76/100\n",
      "35518/35518 [==============================] - 5s 137us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 77/100\n",
      "35518/35518 [==============================] - 5s 137us/step - loss: 0.6930 - acc: 0.5084\n",
      "Epoch 78/100\n",
      "35518/35518 [==============================] - 5s 148us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 79/100\n",
      "35518/35518 [==============================] - 5s 148us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 80/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.6930 - acc: 0.5065\n",
      "Epoch 81/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 82/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 83/100\n",
      "35518/35518 [==============================] - 5s 153us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 84/100\n",
      "35518/35518 [==============================] - 5s 153us/step - loss: 0.6930 - acc: 0.5076\n",
      "Epoch 85/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.6930 - acc: 0.5072\n",
      "Epoch 86/100\n",
      "35518/35518 [==============================] - 5s 155us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 87/100\n",
      "35518/35518 [==============================] - 6s 172us/step - loss: 0.6931 - acc: 0.5075\n",
      "Epoch 88/100\n",
      "35518/35518 [==============================] - 6s 160us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 89/100\n",
      "35518/35518 [==============================] - 5s 146us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 90/100\n",
      "35518/35518 [==============================] - 6s 172us/step - loss: 0.6930 - acc: 0.5078\n",
      "Epoch 91/100\n",
      "35518/35518 [==============================] - 6s 180us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 92/100\n",
      "35518/35518 [==============================] - 5s 138us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 93/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 94/100\n",
      "35518/35518 [==============================] - 5s 144us/step - loss: 0.6930 - acc: 0.5061\n",
      "Epoch 95/100\n",
      "35518/35518 [==============================] - 5s 142us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 96/100\n",
      "35518/35518 [==============================] - 5s 143us/step - loss: 0.6930 - acc: 0.5073\n",
      "Epoch 97/100\n",
      "35518/35518 [==============================] - 6s 161us/step - loss: 0.6930 - acc: 0.5069\n",
      "Epoch 98/100\n",
      "35518/35518 [==============================] - 6s 155us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 99/100\n",
      "35518/35518 [==============================] - 5s 152us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 100/100\n",
      "35518/35518 [==============================] - 6s 173us/step - loss: 0.6931 - acc: 0.5085\n",
      "17495/17495 [==============================] - 1s 40us/step\n",
      "\n",
      "acc: 50.69%\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(32, input_dim=X.shape[1], activation='relu'))\n",
    "model_2.add(Dense(16, input_dim=32, activation='relu'))\n",
    "model_2.add(Dense(14, input_dim=16, activation='relu'))\n",
    "model_2.add(Dense(12, input_dim=14, activation='relu'))\n",
    "model_2.add(Dense(10, input_dim=12, activation='relu'))\n",
    "model_2.add(Dense(8, input_dim=10, activation='relu'))\n",
    "model_2.add(Dense(6, input_dim=8, activation='relu'))\n",
    "model_2.add(Dense(1, input_dim=6, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_2.fit(X_train, y_train, epochs=100, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model_2.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model_2.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model_2.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 3: 16 capas, 100 épocas de entrenamiento, pérdida con función *binary_crossentropy*, Adam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35518/35518 [==============================] - 8s 223us/step - loss: 0.6930 - acc: 0.5090\n",
      "Epoch 2/100\n",
      "35518/35518 [==============================] - 7s 191us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 3/100\n",
      "35518/35518 [==============================] - 6s 180us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 4/100\n",
      "35518/35518 [==============================] - 6s 164us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 5/100\n",
      "35518/35518 [==============================] - 6s 177us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 6/100\n",
      "35518/35518 [==============================] - 5s 144us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 7/100\n",
      "35518/35518 [==============================] - 5s 142us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 8/100\n",
      "35518/35518 [==============================] - 5s 140us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 9/100\n",
      "35518/35518 [==============================] - 5s 139us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 10/100\n",
      "35518/35518 [==============================] - 5s 152us/step - loss: 0.6930 - acc: 0.5082\n",
      "Epoch 11/100\n",
      "35518/35518 [==============================] - 5s 142us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 12/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 13/100\n",
      "35518/35518 [==============================] - 5s 141us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 14/100\n",
      "35518/35518 [==============================] - 6s 163us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 15/100\n",
      "35518/35518 [==============================] - 6s 172us/step - loss: 0.6931 - acc: 0.5082\n",
      "Epoch 16/100\n",
      "35518/35518 [==============================] - 6s 167us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 17/100\n",
      "35518/35518 [==============================] - 6s 171us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 18/100\n",
      "35518/35518 [==============================] - 6s 172us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 19/100\n",
      "35518/35518 [==============================] - 6s 179us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 20/100\n",
      "35518/35518 [==============================] - 5s 140us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 21/100\n",
      "35518/35518 [==============================] - 5s 145us/step - loss: 0.6930 - acc: 0.5074\n",
      "Epoch 22/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 23/100\n",
      "35518/35518 [==============================] - 5s 146us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 24/100\n",
      "35518/35518 [==============================] - 5s 140us/step - loss: 0.6930 - acc: 0.5079\n",
      "Epoch 25/100\n",
      "35518/35518 [==============================] - 5s 141us/step - loss: 0.6931 - acc: 0.5077\n",
      "Epoch 26/100\n",
      "35518/35518 [==============================] - 5s 141us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 27/100\n",
      "35518/35518 [==============================] - 5s 146us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 28/100\n",
      "35518/35518 [==============================] - 5s 151us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 29/100\n",
      "35518/35518 [==============================] - 5s 140us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 30/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 31/100\n",
      "35518/35518 [==============================] - 5s 149us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 32/100\n",
      "35518/35518 [==============================] - 5s 139us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 33/100\n",
      "35518/35518 [==============================] - 5s 143us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 34/100\n",
      "35518/35518 [==============================] - 5s 151us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 35/100\n",
      "35518/35518 [==============================] - 5s 153us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 36/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6930 - acc: 0.5054\n",
      "Epoch 37/100\n",
      "35518/35518 [==============================] - 5s 143us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 38/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 39/100\n",
      "35518/35518 [==============================] - 6s 155us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 40/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 41/100\n",
      "35518/35518 [==============================] - 6s 163us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 42/100\n",
      "35518/35518 [==============================] - 5s 148us/step - loss: 0.6930 - acc: 0.5082\n",
      "Epoch 43/100\n",
      "35518/35518 [==============================] - 5s 142us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 44/100\n",
      "35518/35518 [==============================] - 6s 158us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 45/100\n",
      "35518/35518 [==============================] - 5s 140us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 46/100\n",
      "35518/35518 [==============================] - 5s 153us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 47/100\n",
      "35518/35518 [==============================] - 6s 155us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 48/100\n",
      "35518/35518 [==============================] - 6s 165us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 49/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 50/100\n",
      "35518/35518 [==============================] - 6s 179us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 51/100\n",
      "35518/35518 [==============================] - 7s 185us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 52/100\n",
      "35518/35518 [==============================] - 5s 136us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 53/100\n",
      "35518/35518 [==============================] - 5s 149us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 54/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 55/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6931 - acc: 0.5078\n",
      "Epoch 56/100\n",
      "35518/35518 [==============================] - 6s 167us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 57/100\n",
      "35518/35518 [==============================] - 7s 188us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 58/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 59/100\n",
      "35518/35518 [==============================] - 5s 143us/step - loss: 0.6930 - acc: 0.5081\n",
      "Epoch 60/100\n",
      "35518/35518 [==============================] - 5s 151us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 61/100\n",
      "35518/35518 [==============================] - 5s 147us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 62/100\n",
      "35518/35518 [==============================] - 5s 143us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 63/100\n",
      "35518/35518 [==============================] - 5s 145us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 64/100\n",
      "35518/35518 [==============================] - 6s 162us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 65/100\n",
      "35518/35518 [==============================] - 6s 161us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 66/100\n",
      "35518/35518 [==============================] - 6s 164us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 67/100\n",
      "35518/35518 [==============================] - 5s 151us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 68/100\n",
      "35518/35518 [==============================] - 5s 150us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 69/100\n",
      "35518/35518 [==============================] - 6s 158us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 70/100\n",
      "35518/35518 [==============================] - 5s 148us/step - loss: 0.6930 - acc: 0.5081\n",
      "Epoch 71/100\n",
      "35518/35518 [==============================] - 5s 146us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 72/100\n",
      "35518/35518 [==============================] - 5s 141us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 73/100\n",
      "35518/35518 [==============================] - 5s 146us/step - loss: 0.6930 - acc: 0.5075\n",
      "Epoch 74/100\n",
      "35518/35518 [==============================] - 6s 173us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 75/100\n",
      "35518/35518 [==============================] - 5s 152us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 76/100\n",
      "35518/35518 [==============================] - 6s 174us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 77/100\n",
      "35518/35518 [==============================] - 6s 178us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 78/100\n",
      "35518/35518 [==============================] - 6s 164us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 79/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.6930 - acc: 0.5081\n",
      "Epoch 80/100\n",
      "35518/35518 [==============================] - 6s 167us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 81/100\n",
      "35518/35518 [==============================] - 6s 170us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 82/100\n",
      "35518/35518 [==============================] - 6s 173us/step - loss: 0.6930 - acc: 0.5081\n",
      "Epoch 83/100\n",
      "35518/35518 [==============================] - 6s 169us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 84/100\n",
      "35518/35518 [==============================] - 6s 169us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 85/100\n",
      "35518/35518 [==============================] - 6s 177us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 86/100\n",
      "35518/35518 [==============================] - 6s 178us/step - loss: 0.6930 - acc: 0.5077\n",
      "Epoch 87/100\n",
      "35518/35518 [==============================] - 6s 171us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 88/100\n",
      "35518/35518 [==============================] - 6s 178us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 89/100\n",
      "35518/35518 [==============================] - 6s 179us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 90/100\n",
      "35518/35518 [==============================] - 7s 184us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 91/100\n",
      "35518/35518 [==============================] - 6s 181us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 92/100\n",
      "35518/35518 [==============================] - 6s 177us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 93/100\n",
      "35518/35518 [==============================] - 6s 173us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 94/100\n",
      "35518/35518 [==============================] - 6s 170us/step - loss: 0.6930 - acc: 0.5085\n",
      "Epoch 95/100\n",
      "35518/35518 [==============================] - 6s 168us/step - loss: 0.6930 - acc: 0.5079\n",
      "Epoch 96/100\n",
      "35518/35518 [==============================] - 6s 176us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 97/100\n",
      "35518/35518 [==============================] - 6s 177us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 98/100\n",
      "35518/35518 [==============================] - 7s 210us/step - loss: 0.6931 - acc: 0.5085\n",
      "Epoch 99/100\n",
      "35518/35518 [==============================] - 6s 179us/step - loss: 0.6930 - acc: 0.5081\n",
      "Epoch 100/100\n",
      "35518/35518 [==============================] - 7s 192us/step - loss: 0.6930 - acc: 0.5085\n",
      "17495/17495 [==============================] - 1s 49us/step\n",
      "\n",
      "acc: 50.69%\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Dense(48, input_dim=X.shape[1], activation='relu'))\n",
    "model_3.add(Dense(46, input_dim=48, activation='relu'))\n",
    "model_3.add(Dense(44, input_dim=46, activation='relu'))\n",
    "model_3.add(Dense(42, input_dim=44, activation='relu'))\n",
    "model_3.add(Dense(40, input_dim=42, activation='relu'))\n",
    "model_3.add(Dense(38, input_dim=40, activation='relu'))\n",
    "model_3.add(Dense(36, input_dim=38, activation='relu'))\n",
    "model_3.add(Dense(34, input_dim=36, activation='relu'))\n",
    "model_3.add(Dense(32, input_dim=34, activation='relu'))\n",
    "model_3.add(Dense(16, input_dim=32, activation='relu'))\n",
    "model_3.add(Dense(14, input_dim=16, activation='relu'))\n",
    "model_3.add(Dense(12, input_dim=14, activation='relu'))\n",
    "model_3.add(Dense(10, input_dim=12, activation='relu'))\n",
    "model_3.add(Dense(8, input_dim=10, activation='relu'))\n",
    "model_3.add(Dense(6, input_dim=8, activation='relu'))\n",
    "model_3.add(Dense(1, input_dim=6, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model_3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_3.fit(X_train, y_train, epochs=100, batch_size=15)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model_3.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model_3.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model_3.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 4: 4 capas, 100 épocas de entrenamiento, pérdida con función *mean_squared_error*, Adam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35518/35518 [==============================] - 4s 112us/step - loss: 0.2501 - acc: 0.5020\n",
      "Epoch 2/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2496 - acc: 0.5129\n",
      "Epoch 3/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2480 - acc: 0.5300\n",
      "Epoch 4/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2443 - acc: 0.5596\n",
      "Epoch 5/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2393 - acc: 0.5792\n",
      "Epoch 6/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2343 - acc: 0.6008\n",
      "Epoch 7/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2298 - acc: 0.6152\n",
      "Epoch 8/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2262 - acc: 0.6262\n",
      "Epoch 9/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.2225 - acc: 0.6354\n",
      "Epoch 10/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2190 - acc: 0.6446\n",
      "Epoch 11/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2159 - acc: 0.6524\n",
      "Epoch 12/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2132 - acc: 0.6583\n",
      "Epoch 13/100\n",
      "35518/35518 [==============================] - 3s 96us/step - loss: 0.2108 - acc: 0.6681\n",
      "Epoch 14/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.2085 - acc: 0.6730\n",
      "Epoch 15/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2063 - acc: 0.6763\n",
      "Epoch 16/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2046 - acc: 0.6834\n",
      "Epoch 17/100\n",
      "35518/35518 [==============================] - 4s 99us/step - loss: 0.2030 - acc: 0.6868\n",
      "Epoch 18/100\n",
      "35518/35518 [==============================] - 3s 97us/step - loss: 0.2012 - acc: 0.6913\n",
      "Epoch 19/100\n",
      "35518/35518 [==============================] - 3s 97us/step - loss: 0.2001 - acc: 0.6938\n",
      "Epoch 20/100\n",
      "35518/35518 [==============================] - 4s 122us/step - loss: 0.1981 - acc: 0.6973\n",
      "Epoch 21/100\n",
      "35518/35518 [==============================] - 3s 91us/step - loss: 0.1971 - acc: 0.7003\n",
      "Epoch 22/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.1956 - acc: 0.7035\n",
      "Epoch 23/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.1948 - acc: 0.7043\n",
      "Epoch 24/100\n",
      "35518/35518 [==============================] - 4s 102us/step - loss: 0.1941 - acc: 0.7053\n",
      "Epoch 25/100\n",
      "35518/35518 [==============================] - 4s 101us/step - loss: 0.1923 - acc: 0.7102\n",
      "Epoch 26/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.1916 - acc: 0.7121\n",
      "Epoch 27/100\n",
      "35518/35518 [==============================] - 3s 96us/step - loss: 0.1911 - acc: 0.7112\n",
      "Epoch 28/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.1896 - acc: 0.7168\n",
      "Epoch 29/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.1889 - acc: 0.7172\n",
      "Epoch 30/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.1880 - acc: 0.7214\n",
      "Epoch 31/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.1873 - acc: 0.7219\n",
      "Epoch 32/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.1861 - acc: 0.7258\n",
      "Epoch 33/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.1850 - acc: 0.7275\n",
      "Epoch 34/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.1849 - acc: 0.7279\n",
      "Epoch 35/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.1837 - acc: 0.7328\n",
      "Epoch 36/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.1830 - acc: 0.7310\n",
      "Epoch 37/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.1822 - acc: 0.7328\n",
      "Epoch 38/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.1816 - acc: 0.7362\n",
      "Epoch 39/100\n",
      "35518/35518 [==============================] - 4s 102us/step - loss: 0.1816 - acc: 0.7349\n",
      "Epoch 40/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.1809 - acc: 0.7389\n",
      "Epoch 41/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.1804 - acc: 0.7394\n",
      "Epoch 42/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.1801 - acc: 0.7395\n",
      "Epoch 43/100\n",
      "35518/35518 [==============================] - 3s 94us/step - loss: 0.1791 - acc: 0.7439\n",
      "Epoch 44/100\n",
      "35518/35518 [==============================] - 4s 99us/step - loss: 0.1784 - acc: 0.7432\n",
      "Epoch 45/100\n",
      "35518/35518 [==============================] - 3s 96us/step - loss: 0.1783 - acc: 0.7431\n",
      "Epoch 46/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.1777 - acc: 0.7460\n",
      "Epoch 47/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.1777 - acc: 0.7442\n",
      "Epoch 48/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.1764 - acc: 0.7471\n",
      "Epoch 49/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.1761 - acc: 0.7482\n",
      "Epoch 50/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.1762 - acc: 0.7486\n",
      "Epoch 51/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.1759 - acc: 0.7479\n",
      "Epoch 52/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.1746 - acc: 0.7532\n",
      "Epoch 53/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.1741 - acc: 0.7525\n",
      "Epoch 54/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.1747 - acc: 0.7531\n",
      "Epoch 55/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.1743 - acc: 0.7519\n",
      "Epoch 56/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.1734 - acc: 0.7545\n",
      "Epoch 57/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.1734 - acc: 0.7539\n",
      "Epoch 58/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.1726 - acc: 0.7553\n",
      "Epoch 59/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.1726 - acc: 0.7574\n",
      "Epoch 60/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.1724 - acc: 0.7575\n",
      "Epoch 61/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.1723 - acc: 0.7574\n",
      "Epoch 62/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.1713 - acc: 0.7590\n",
      "Epoch 63/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.1715 - acc: 0.7602\n",
      "Epoch 64/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.1709 - acc: 0.7596\n",
      "Epoch 65/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.1711 - acc: 0.7591\n",
      "Epoch 66/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.1705 - acc: 0.7595\n",
      "Epoch 67/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.1702 - acc: 0.7616\n",
      "Epoch 68/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.1704 - acc: 0.7598\n",
      "Epoch 69/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.1693 - acc: 0.7622\n",
      "Epoch 70/100\n",
      "35518/35518 [==============================] - 3s 98us/step - loss: 0.1695 - acc: 0.7632\n",
      "Epoch 71/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.1688 - acc: 0.7635\n",
      "Epoch 72/100\n",
      "35518/35518 [==============================] - 3s 91us/step - loss: 0.1688 - acc: 0.7630\n",
      "Epoch 73/100\n",
      "35518/35518 [==============================] - 3s 95us/step - loss: 0.1686 - acc: 0.7636\n",
      "Epoch 74/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.1681 - acc: 0.7652\n",
      "Epoch 75/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.1679 - acc: 0.7647\n",
      "Epoch 76/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.1675 - acc: 0.7687\n",
      "Epoch 77/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.1670 - acc: 0.7687\n",
      "Epoch 78/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.1672 - acc: 0.7673\n",
      "Epoch 79/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.1668 - acc: 0.7679\n",
      "Epoch 80/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.1660 - acc: 0.7696\n",
      "Epoch 81/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.1661 - acc: 0.7696\n",
      "Epoch 82/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.1660 - acc: 0.7688\n",
      "Epoch 83/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.1658 - acc: 0.7708\n",
      "Epoch 84/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.1660 - acc: 0.7713\n",
      "Epoch 85/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.1657 - acc: 0.7720\n",
      "Epoch 86/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.1659 - acc: 0.7692\n",
      "Epoch 87/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.1649 - acc: 0.7726\n",
      "Epoch 88/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.1649 - acc: 0.7719\n",
      "Epoch 89/100\n",
      "35518/35518 [==============================] - 3s 97us/step - loss: 0.1641 - acc: 0.7733\n",
      "Epoch 90/100\n",
      "35518/35518 [==============================] - 3s 98us/step - loss: 0.1644 - acc: 0.7746\n",
      "Epoch 91/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.1643 - acc: 0.7735\n",
      "Epoch 92/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.1640 - acc: 0.7738\n",
      "Epoch 93/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.1632 - acc: 0.7753\n",
      "Epoch 94/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.1635 - acc: 0.7750\n",
      "Epoch 95/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.1629 - acc: 0.7770\n",
      "Epoch 96/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.1633 - acc: 0.7752\n",
      "Epoch 97/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.1630 - acc: 0.7752\n",
      "Epoch 98/100\n",
      "35518/35518 [==============================] - 4s 108us/step - loss: 0.1621 - acc: 0.7777\n",
      "Epoch 99/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.1628 - acc: 0.7761\n",
      "Epoch 100/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.1623 - acc: 0.7780\n",
      "17495/17495 [==============================] - 1s 37us/step\n",
      "TEST: \n",
      "\n",
      "acc: 50.19%\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Dense(16, input_dim=X.shape[1], activation='relu'))\n",
    "model_4.add(Dense(8, input_dim=16, activation='relu'))\n",
    "model_4.add(Dense(8, input_dim=8, activation='relu'))\n",
    "model_4.add(Dense(1, input_dim=8, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model_4.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_4.fit(X_train, y_train, epochs=100, batch_size=15)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model_4.evaluate(X_test, y_test)\n",
    "print('TEST: ')\n",
    "print(\"\\n%s: %.2f%%\" % (model_4.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model_4.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 5: 4 capas, 100 épocas de entrenamiento, pérdida con función *squared_hinge*, Adam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35518/35518 [==============================] - 4s 114us/step - loss: 0.4927 - acc: 0.5084\n",
      "Epoch 2/100\n",
      "35518/35518 [==============================] - 4s 100us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 3/100\n",
      "35518/35518 [==============================] - 3s 97us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 4/100\n",
      "35518/35518 [==============================] - 4s 102us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 5/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 6/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 7/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 8/100\n",
      "35518/35518 [==============================] - 4s 99us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 9/100\n",
      "35518/35518 [==============================] - 4s 102us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 10/100\n",
      "35518/35518 [==============================] - 3s 96us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 11/100\n",
      "35518/35518 [==============================] - 4s 101us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 12/100\n",
      "35518/35518 [==============================] - 4s 103us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 13/100\n",
      "35518/35518 [==============================] - 3s 94us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 14/100\n",
      "35518/35518 [==============================] - 4s 102us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 15/100\n",
      "35518/35518 [==============================] - 3s 94us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 16/100\n",
      "35518/35518 [==============================] - 4s 102us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 17/100\n",
      "35518/35518 [==============================] - 3s 94us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 18/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 19/100\n",
      "35518/35518 [==============================] - 3s 91us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 20/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 21/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 22/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 23/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 24/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 25/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 26/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 27/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 28/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 29/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 30/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 31/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 32/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 33/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 34/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 35/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 36/100\n",
      "35518/35518 [==============================] - 3s 96us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 37/100\n",
      "35518/35518 [==============================] - 4s 101us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 38/100\n",
      "35518/35518 [==============================] - 4s 103us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 39/100\n",
      "35518/35518 [==============================] - 4s 106us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 40/100\n",
      "35518/35518 [==============================] - 4s 121us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 41/100\n",
      "35518/35518 [==============================] - 4s 101us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 42/100\n",
      "35518/35518 [==============================] - 4s 103us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 43/100\n",
      "35518/35518 [==============================] - 3s 98us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 44/100\n",
      "35518/35518 [==============================] - 3s 91us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 45/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 46/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 47/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 48/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 49/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 50/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 51/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 52/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 53/100\n",
      "35518/35518 [==============================] - 3s 98us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 54/100\n",
      "35518/35518 [==============================] - 3s 91us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 55/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 56/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 57/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 58/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 59/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 60/100\n",
      "35518/35518 [==============================] - 3s 91us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 61/100\n",
      "35518/35518 [==============================] - 4s 99us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 62/100\n",
      "35518/35518 [==============================] - 4s 101us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 63/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 64/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 65/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 66/100\n",
      "35518/35518 [==============================] - 3s 91us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 67/100\n",
      "35518/35518 [==============================] - 4s 100us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 68/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 69/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 70/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 71/100\n",
      "35518/35518 [==============================] - 3s 98us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 72/100\n",
      "35518/35518 [==============================] - 3s 91us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 73/100\n",
      "35518/35518 [==============================] - 3s 91us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 74/100\n",
      "35518/35518 [==============================] - 3s 97us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 75/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 76/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 77/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 78/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 79/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 80/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 81/100\n",
      "35518/35518 [==============================] - 3s 94us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 82/100\n",
      "35518/35518 [==============================] - 3s 95us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 83/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 84/100\n",
      "35518/35518 [==============================] - 3s 95us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 85/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 86/100\n",
      "35518/35518 [==============================] - 3s 91us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 87/100\n",
      "35518/35518 [==============================] - 4s 108us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 88/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 89/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 90/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 91/100\n",
      "35518/35518 [==============================] - 3s 94us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 92/100\n",
      "35518/35518 [==============================] - 3s 91us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 93/100\n",
      "35518/35518 [==============================] - 3s 98us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 94/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 95/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 96/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 97/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 98/100\n",
      "35518/35518 [==============================] - 3s 99us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 99/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.4915 - acc: 0.5085\n",
      "Epoch 100/100\n",
      "35518/35518 [==============================] - 3s 97us/step - loss: 0.4915 - acc: 0.5085\n",
      "17495/17495 [==============================] - 1s 39us/step\n",
      "TEST: \n",
      "\n",
      "acc: 50.69%\n"
     ]
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(Dense(16, input_dim=X.shape[1], activation='relu'))\n",
    "model_5.add(Dense(8, input_dim=16, activation='relu'))\n",
    "model_5.add(Dense(8, input_dim=8, activation='relu'))\n",
    "model_5.add(Dense(1, input_dim=8, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model_5.compile(loss='squared_hinge', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_5.fit(X_train, y_train, epochs=100, batch_size=15)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model_5.evaluate(X_test, y_test)\n",
    "print('TEST: ')\n",
    "print(\"\\n%s: %.2f%%\" % (model_5.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model_5.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 6: 4 capas, 100 épocas de entrenamiento, pérdida con función *mean_squared_error* , *Stochastic gradient descent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35518/35518 [==============================] - 4s 106us/step - loss: 0.2501 - acc: 0.5015\n",
      "Epoch 2/100\n",
      "35518/35518 [==============================] - 3s 90us/step - loss: 0.2500 - acc: 0.5028\n",
      "Epoch 3/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2499 - acc: 0.5075\n",
      "Epoch 4/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2499 - acc: 0.5082\n",
      "Epoch 5/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.2498 - acc: 0.5130\n",
      "Epoch 6/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.2498 - acc: 0.5130\n",
      "Epoch 7/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.2497 - acc: 0.5146\n",
      "Epoch 8/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.2497 - acc: 0.5147\n",
      "Epoch 9/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2496 - acc: 0.5155\n",
      "Epoch 10/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2496 - acc: 0.5167\n",
      "Epoch 11/100\n",
      "35518/35518 [==============================] - 3s 75us/step - loss: 0.2496 - acc: 0.5172\n",
      "Epoch 12/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2495 - acc: 0.5218\n",
      "Epoch 13/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2494 - acc: 0.5213\n",
      "Epoch 14/100\n",
      "35518/35518 [==============================] - 3s 76us/step - loss: 0.2494 - acc: 0.5220\n",
      "Epoch 15/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2493 - acc: 0.5255\n",
      "Epoch 16/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2492 - acc: 0.5275\n",
      "Epoch 17/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2491 - acc: 0.5296\n",
      "Epoch 18/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2490 - acc: 0.5286\n",
      "Epoch 19/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.2489 - acc: 0.5332\n",
      "Epoch 20/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.2487 - acc: 0.5338\n",
      "Epoch 21/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2486 - acc: 0.5371\n",
      "Epoch 22/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2484 - acc: 0.5398\n",
      "Epoch 23/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2483 - acc: 0.5421\n",
      "Epoch 24/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.2481 - acc: 0.5440\n",
      "Epoch 25/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.2479 - acc: 0.5463\n",
      "Epoch 26/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2477 - acc: 0.5483\n",
      "Epoch 27/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.2475 - acc: 0.5515\n",
      "Epoch 28/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.2473 - acc: 0.5512\n",
      "Epoch 29/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2470 - acc: 0.5535\n",
      "Epoch 30/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.2468 - acc: 0.5569\n",
      "Epoch 31/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.2465 - acc: 0.5575\n",
      "Epoch 32/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2462 - acc: 0.5581\n",
      "Epoch 33/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2459 - acc: 0.5612\n",
      "Epoch 34/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.2455 - acc: 0.5628\n",
      "Epoch 35/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.2452 - acc: 0.5640\n",
      "Epoch 36/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2448 - acc: 0.5681\n",
      "Epoch 37/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.2444 - acc: 0.5686\n",
      "Epoch 38/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2440 - acc: 0.5723\n",
      "Epoch 39/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2435 - acc: 0.5724\n",
      "Epoch 40/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.2431 - acc: 0.5777\n",
      "Epoch 41/100\n",
      "35518/35518 [==============================] - 3s 75us/step - loss: 0.2427 - acc: 0.5779\n",
      "Epoch 42/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2421 - acc: 0.5797\n",
      "Epoch 43/100\n",
      "35518/35518 [==============================] - 3s 75us/step - loss: 0.2416 - acc: 0.5840\n",
      "Epoch 44/100\n",
      "35518/35518 [==============================] - 3s 75us/step - loss: 0.2411 - acc: 0.5850\n",
      "Epoch 45/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2405 - acc: 0.5884\n",
      "Epoch 46/100\n",
      "35518/35518 [==============================] - 4s 109us/step - loss: 0.2399 - acc: 0.5911\n",
      "Epoch 47/100\n",
      "35518/35518 [==============================] - 7s 205us/step - loss: 0.2392 - acc: 0.5929\n",
      "Epoch 48/100\n",
      "35518/35518 [==============================] - 14s 393us/step - loss: 0.2386 - acc: 0.5972\n",
      "Epoch 49/100\n",
      "35518/35518 [==============================] - 12s 344us/step - loss: 0.2380 - acc: 0.5994\n",
      "Epoch 50/100\n",
      "35518/35518 [==============================] - 9s 248us/step - loss: 0.2373 - acc: 0.6021\n",
      "Epoch 51/100\n",
      "35518/35518 [==============================] - 7s 204us/step - loss: 0.2366 - acc: 0.6052\n",
      "Epoch 52/100\n",
      "35518/35518 [==============================] - 6s 161us/step - loss: 0.2359 - acc: 0.6063\n",
      "Epoch 53/100\n",
      "35518/35518 [==============================] - 5s 140us/step - loss: 0.2351 - acc: 0.6088\n",
      "Epoch 54/100\n",
      "35518/35518 [==============================] - 3s 94us/step - loss: 0.2343 - acc: 0.6132\n",
      "Epoch 55/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.2336 - acc: 0.6132\n",
      "Epoch 56/100\n",
      "35518/35518 [==============================] - 3s 95us/step - loss: 0.2328 - acc: 0.6193\n",
      "Epoch 57/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.2320 - acc: 0.6211\n",
      "Epoch 58/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2313 - acc: 0.6226\n",
      "Epoch 59/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.2305 - acc: 0.6254\n",
      "Epoch 60/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.2297 - acc: 0.6288\n",
      "Epoch 61/100\n",
      "35518/35518 [==============================] - 3s 76us/step - loss: 0.2290 - acc: 0.6300\n",
      "Epoch 62/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2282 - acc: 0.6333\n",
      "Epoch 63/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2275 - acc: 0.6343\n",
      "Epoch 64/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2266 - acc: 0.6367\n",
      "Epoch 65/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2259 - acc: 0.6381\n",
      "Epoch 66/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2252 - acc: 0.6413\n",
      "Epoch 67/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.2244 - acc: 0.6432\n",
      "Epoch 68/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2237 - acc: 0.6458\n",
      "Epoch 69/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2230 - acc: 0.6486\n",
      "Epoch 70/100\n",
      "35518/35518 [==============================] - 3s 75us/step - loss: 0.2222 - acc: 0.6515\n",
      "Epoch 71/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2214 - acc: 0.6531\n",
      "Epoch 72/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2209 - acc: 0.6538\n",
      "Epoch 73/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2202 - acc: 0.6554\n",
      "Epoch 74/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2193 - acc: 0.6575\n",
      "Epoch 75/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2188 - acc: 0.6603\n",
      "Epoch 76/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2182 - acc: 0.6601\n",
      "Epoch 77/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2175 - acc: 0.6628\n",
      "Epoch 78/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2168 - acc: 0.6665\n",
      "Epoch 79/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2162 - acc: 0.6675\n",
      "Epoch 80/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2157 - acc: 0.6703\n",
      "Epoch 81/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2149 - acc: 0.6697\n",
      "Epoch 82/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2143 - acc: 0.6730\n",
      "Epoch 83/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2137 - acc: 0.6716\n",
      "Epoch 84/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.2132 - acc: 0.6745\n",
      "Epoch 85/100\n",
      "35518/35518 [==============================] - 4s 105us/step - loss: 0.2127 - acc: 0.6771\n",
      "Epoch 86/100\n",
      "35518/35518 [==============================] - 6s 169us/step - loss: 0.2121 - acc: 0.6790\n",
      "Epoch 87/100\n",
      "35518/35518 [==============================] - 4s 115us/step - loss: 0.2115 - acc: 0.6786\n",
      "Epoch 88/100\n",
      "35518/35518 [==============================] - 4s 115us/step - loss: 0.2108 - acc: 0.6810\n",
      "Epoch 89/100\n",
      "35518/35518 [==============================] - 3s 95us/step - loss: 0.2103 - acc: 0.6821\n",
      "Epoch 90/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2099 - acc: 0.6840\n",
      "Epoch 91/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.2092 - acc: 0.6848\n",
      "Epoch 92/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.2089 - acc: 0.6873\n",
      "Epoch 93/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2082 - acc: 0.6866\n",
      "Epoch 94/100\n",
      "35518/35518 [==============================] - 3s 76us/step - loss: 0.2080 - acc: 0.6899\n",
      "Epoch 95/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2075 - acc: 0.6876\n",
      "Epoch 96/100\n",
      "35518/35518 [==============================] - 3s 75us/step - loss: 0.2069 - acc: 0.6914\n",
      "Epoch 97/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2060 - acc: 0.6924\n",
      "Epoch 98/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2056 - acc: 0.6948\n",
      "Epoch 99/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2050 - acc: 0.6972\n",
      "Epoch 100/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2047 - acc: 0.6970\n",
      "17495/17495 [==============================] - 1s 37us/step\n",
      "TEST: \n",
      "\n",
      "acc: 50.62%\n"
     ]
    }
   ],
   "source": [
    "model_6 = Sequential()\n",
    "model_6.add(Dense(16, input_dim=X.shape[1], activation='relu'))\n",
    "model_6.add(Dense(8, input_dim=16, activation='relu'))\n",
    "model_6.add(Dense(8, input_dim=8, activation='relu'))\n",
    "model_6.add(Dense(1, input_dim=8, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model_6.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_6.fit(X_train, y_train, epochs=100, batch_size=15)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model_6.evaluate(X_test, y_test)\n",
    "print('TEST: ')\n",
    "print(\"\\n%s: %.2f%%\" % (model_6.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model_6.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 7: 3 capas + *softmax*, 100 épocas de entrenamiento, pérdida con función *mean_squared_error*, *Stochastic gradient descent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35518/35518 [==============================] - 4s 106us/step - loss: 0.2504 - acc: 0.5007\n",
      "Epoch 2/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.2501 - acc: 0.5046\n",
      "Epoch 3/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.2500 - acc: 0.5081\n",
      "Epoch 4/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2499 - acc: 0.5065\n",
      "Epoch 5/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.2499 - acc: 0.5111\n",
      "Epoch 6/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.2498 - acc: 0.5127\n",
      "Epoch 7/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.2497 - acc: 0.5139\n",
      "Epoch 8/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2497 - acc: 0.5151\n",
      "Epoch 9/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.2496 - acc: 0.5161\n",
      "Epoch 10/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.2496 - acc: 0.5185\n",
      "Epoch 11/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.2495 - acc: 0.5178\n",
      "Epoch 12/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2494 - acc: 0.5208\n",
      "Epoch 13/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.2494 - acc: 0.5212\n",
      "Epoch 14/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2493 - acc: 0.5235\n",
      "Epoch 15/100\n",
      "35518/35518 [==============================] - 3s 92us/step - loss: 0.2492 - acc: 0.5235\n",
      "Epoch 16/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2491 - acc: 0.5246\n",
      "Epoch 17/100\n",
      "35518/35518 [==============================] - 3s 96us/step - loss: 0.2490 - acc: 0.5270\n",
      "Epoch 18/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2490 - acc: 0.5256\n",
      "Epoch 19/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.2489 - acc: 0.5265\n",
      "Epoch 20/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2488 - acc: 0.5301\n",
      "Epoch 21/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.2487 - acc: 0.5298\n",
      "Epoch 22/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.2486 - acc: 0.5322\n",
      "Epoch 23/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.2484 - acc: 0.5327\n",
      "Epoch 24/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.2483 - acc: 0.5341\n",
      "Epoch 25/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.2482 - acc: 0.5355\n",
      "Epoch 26/100\n",
      "35518/35518 [==============================] - 3s 88us/step - loss: 0.2480 - acc: 0.5353\n",
      "Epoch 27/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2479 - acc: 0.5384\n",
      "Epoch 28/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.2477 - acc: 0.5398\n",
      "Epoch 29/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.2475 - acc: 0.5412\n",
      "Epoch 30/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2473 - acc: 0.5440\n",
      "Epoch 31/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2471 - acc: 0.5442\n",
      "Epoch 32/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2469 - acc: 0.5438\n",
      "Epoch 33/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.2466 - acc: 0.5475\n",
      "Epoch 34/100\n",
      "35518/35518 [==============================] - 3s 89us/step - loss: 0.2464 - acc: 0.5494\n",
      "Epoch 35/100\n",
      "35518/35518 [==============================] - 3s 95us/step - loss: 0.2462 - acc: 0.5509\n",
      "Epoch 36/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2459 - acc: 0.5537\n",
      "Epoch 37/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2455 - acc: 0.5574\n",
      "Epoch 38/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.2452 - acc: 0.5589\n",
      "Epoch 39/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.2449 - acc: 0.5613\n",
      "Epoch 40/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.2444 - acc: 0.5632\n",
      "Epoch 41/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2441 - acc: 0.5652\n",
      "Epoch 42/100\n",
      "35518/35518 [==============================] - 3s 76us/step - loss: 0.2436 - acc: 0.5672\n",
      "Epoch 43/100\n",
      "35518/35518 [==============================] - 2s 65us/step - loss: 0.2432 - acc: 0.5699\n",
      "Epoch 44/100\n",
      "35518/35518 [==============================] - 3s 86us/step - loss: 0.2427 - acc: 0.5721\n",
      "Epoch 45/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.2423 - acc: 0.5744\n",
      "Epoch 46/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2417 - acc: 0.5748\n",
      "Epoch 47/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2412 - acc: 0.5789\n",
      "Epoch 48/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.2407 - acc: 0.5807\n",
      "Epoch 49/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2401 - acc: 0.5820\n",
      "Epoch 50/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2396 - acc: 0.5852\n",
      "Epoch 51/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2390 - acc: 0.5875\n",
      "Epoch 52/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2384 - acc: 0.5899\n",
      "Epoch 53/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2378 - acc: 0.5916\n",
      "Epoch 54/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2372 - acc: 0.5936\n",
      "Epoch 55/100\n",
      "35518/35518 [==============================] - 3s 93us/step - loss: 0.2366 - acc: 0.5964\n",
      "Epoch 56/100\n",
      "35518/35518 [==============================] - 3s 87us/step - loss: 0.2359 - acc: 0.5987\n",
      "Epoch 57/100\n",
      "35518/35518 [==============================] - 3s 85us/step - loss: 0.2352 - acc: 0.6024\n",
      "Epoch 58/100\n",
      "35518/35518 [==============================] - 3s 82us/step - loss: 0.2346 - acc: 0.6042\n",
      "Epoch 59/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2339 - acc: 0.6071\n",
      "Epoch 60/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2333 - acc: 0.6091\n",
      "Epoch 61/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2325 - acc: 0.6117\n",
      "Epoch 62/100\n",
      "35518/35518 [==============================] - 3s 84us/step - loss: 0.2319 - acc: 0.6150\n",
      "Epoch 63/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2313 - acc: 0.6170\n",
      "Epoch 64/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2304 - acc: 0.6178\n",
      "Epoch 65/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2297 - acc: 0.6194\n",
      "Epoch 66/100\n",
      "35518/35518 [==============================] - 3s 81us/step - loss: 0.2291 - acc: 0.6246\n",
      "Epoch 67/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2283 - acc: 0.6252\n",
      "Epoch 68/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2276 - acc: 0.6273\n",
      "Epoch 69/100\n",
      "35518/35518 [==============================] - 3s 80us/step - loss: 0.2269 - acc: 0.6288\n",
      "Epoch 70/100\n",
      "35518/35518 [==============================] - 3s 83us/step - loss: 0.2262 - acc: 0.6323\n",
      "Epoch 71/100\n",
      "35518/35518 [==============================] - 3s 95us/step - loss: 0.2255 - acc: 0.6350\n",
      "Epoch 72/100\n",
      "35518/35518 [==============================] - 6s 178us/step - loss: 0.2248 - acc: 0.6374\n",
      "Epoch 73/100\n",
      "35518/35518 [==============================] - 7s 205us/step - loss: 0.2241 - acc: 0.6401\n",
      "Epoch 74/100\n",
      "35518/35518 [==============================] - 9s 242us/step - loss: 0.2234 - acc: 0.6410\n",
      "Epoch 75/100\n",
      "35518/35518 [==============================] - 8s 237us/step - loss: 0.2228 - acc: 0.6413\n",
      "Epoch 76/100\n",
      "35518/35518 [==============================] - 4s 111us/step - loss: 0.2221 - acc: 0.6449\n",
      "Epoch 77/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2214 - acc: 0.6469\n",
      "Epoch 78/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2208 - acc: 0.6474\n",
      "Epoch 79/100\n",
      "35518/35518 [==============================] - 3s 76us/step - loss: 0.2202 - acc: 0.6508\n",
      "Epoch 80/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2193 - acc: 0.6540\n",
      "Epoch 81/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2187 - acc: 0.6539\n",
      "Epoch 82/100\n",
      "35518/35518 [==============================] - 3s 76us/step - loss: 0.2183 - acc: 0.6552\n",
      "Epoch 83/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2175 - acc: 0.6568\n",
      "Epoch 84/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2171 - acc: 0.6602\n",
      "Epoch 85/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2165 - acc: 0.6605\n",
      "Epoch 86/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2159 - acc: 0.6634\n",
      "Epoch 87/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2152 - acc: 0.6658\n",
      "Epoch 88/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2147 - acc: 0.6636\n",
      "Epoch 89/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2140 - acc: 0.6679\n",
      "Epoch 90/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2138 - acc: 0.6689\n",
      "Epoch 91/100\n",
      "35518/35518 [==============================] - 3s 79us/step - loss: 0.2130 - acc: 0.6700\n",
      "Epoch 92/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2125 - acc: 0.6706\n",
      "Epoch 93/100\n",
      "35518/35518 [==============================] - 3s 76us/step - loss: 0.2120 - acc: 0.6708\n",
      "Epoch 94/100\n",
      "35518/35518 [==============================] - 3s 76us/step - loss: 0.2113 - acc: 0.6723\n",
      "Epoch 95/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2111 - acc: 0.6720\n",
      "Epoch 96/100\n",
      "35518/35518 [==============================] - 3s 76us/step - loss: 0.2104 - acc: 0.6758\n",
      "Epoch 97/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2099 - acc: 0.6769\n",
      "Epoch 98/100\n",
      "35518/35518 [==============================] - 3s 77us/step - loss: 0.2095 - acc: 0.6794\n",
      "Epoch 99/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2089 - acc: 0.6817\n",
      "Epoch 100/100\n",
      "35518/35518 [==============================] - 3s 78us/step - loss: 0.2084 - acc: 0.6816\n",
      "17495/17495 [==============================] - 1s 41us/step\n",
      "TEST: \n",
      "\n",
      "acc: 50.40%\n"
     ]
    }
   ],
   "source": [
    "model_7 = Sequential()\n",
    "model_7.add(Dense(16, input_dim=X.shape[1], activation='relu'))\n",
    "model_7.add(Dense(8, input_dim=16, activation='relu'))\n",
    "model_7.add(Dense(8, input_dim=8, activation='relu'))\n",
    "model_7.add(Dense(1, input_dim=8, activation='sigmoid'))\n",
    "# Compile model\n",
    "model_7.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_7.fit(X_train, y_train, epochs=100, batch_size=15)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model_7.evaluate(X_test, y_test)\n",
    "print('TEST: ')\n",
    "print(\"\\n%s: %.2f%%\" % (model_7.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model_7.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 8: 4 capas, 100 épocas de entrenamiento, pérdida con función *logcosh*, *Stochastic gradient descent*, batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35518/35518 [==============================] - 7s 203us/step - loss: 0.1202 - acc: 0.5035\n",
      "Epoch 2/100\n",
      "35518/35518 [==============================] - 6s 175us/step - loss: 0.1198 - acc: 0.5177\n",
      "Epoch 3/100\n",
      "35518/35518 [==============================] - 6s 181us/step - loss: 0.1184 - acc: 0.5438\n",
      "Epoch 4/100\n",
      "35518/35518 [==============================] - 6s 176us/step - loss: 0.1154 - acc: 0.5755\n",
      "Epoch 5/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.1105 - acc: 0.6100\n",
      "Epoch 6/100\n",
      "35518/35518 [==============================] - 6s 170us/step - loss: 0.1043 - acc: 0.6463\n",
      "Epoch 7/100\n",
      "35518/35518 [==============================] - 6s 159us/step - loss: 0.0983 - acc: 0.6744\n",
      "Epoch 8/100\n",
      "35518/35518 [==============================] - 6s 165us/step - loss: 0.0925 - acc: 0.7005\n",
      "Epoch 9/100\n",
      "35518/35518 [==============================] - 6s 166us/step - loss: 0.0870 - acc: 0.7251\n",
      "Epoch 10/100\n",
      "35518/35518 [==============================] - 6s 169us/step - loss: 0.0822 - acc: 0.7457\n",
      "Epoch 11/100\n",
      "35518/35518 [==============================] - 6s 155us/step - loss: 0.0774 - acc: 0.7634\n",
      "Epoch 12/100\n",
      "35518/35518 [==============================] - 6s 168us/step - loss: 0.0730 - acc: 0.7809\n",
      "Epoch 13/100\n",
      "35518/35518 [==============================] - 6s 159us/step - loss: 0.0692 - acc: 0.7949\n",
      "Epoch 14/100\n",
      "35518/35518 [==============================] - 6s 159us/step - loss: 0.0656 - acc: 0.8069\n",
      "Epoch 15/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.0617 - acc: 0.8218\n",
      "Epoch 16/100\n",
      "35518/35518 [==============================] - 6s 158us/step - loss: 0.0588 - acc: 0.8322\n",
      "Epoch 17/100\n",
      "35518/35518 [==============================] - 6s 160us/step - loss: 0.0558 - acc: 0.8435\n",
      "Epoch 18/100\n",
      "35518/35518 [==============================] - 6s 162us/step - loss: 0.0529 - acc: 0.8526\n",
      "Epoch 19/100\n",
      "35518/35518 [==============================] - 6s 168us/step - loss: 0.0504 - acc: 0.8603\n",
      "Epoch 20/100\n",
      "35518/35518 [==============================] - 6s 161us/step - loss: 0.0479 - acc: 0.8698\n",
      "Epoch 21/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.0456 - acc: 0.8755\n",
      "Epoch 22/100\n",
      "35518/35518 [==============================] - 6s 167us/step - loss: 0.0435 - acc: 0.8829\n",
      "Epoch 23/100\n",
      "35518/35518 [==============================] - 6s 161us/step - loss: 0.0417 - acc: 0.8885\n",
      "Epoch 24/100\n",
      "35518/35518 [==============================] - 6s 158us/step - loss: 0.0398 - acc: 0.8948\n",
      "Epoch 25/100\n",
      "35518/35518 [==============================] - 7s 185us/step - loss: 0.0377 - acc: 0.9009\n",
      "Epoch 26/100\n",
      "35518/35518 [==============================] - 7s 184us/step - loss: 0.0363 - acc: 0.9049\n",
      "Epoch 27/100\n",
      "35518/35518 [==============================] - 6s 164us/step - loss: 0.0349 - acc: 0.9102\n",
      "Epoch 28/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.0333 - acc: 0.9139\n",
      "Epoch 29/100\n",
      "35518/35518 [==============================] - 5s 150us/step - loss: 0.0320 - acc: 0.9177\n",
      "Epoch 30/100\n",
      "35518/35518 [==============================] - 5s 152us/step - loss: 0.0308 - acc: 0.9215\n",
      "Epoch 31/100\n",
      "35518/35518 [==============================] - 5s 151us/step - loss: 0.0297 - acc: 0.9238\n",
      "Epoch 32/100\n",
      "35518/35518 [==============================] - 5s 150us/step - loss: 0.0286 - acc: 0.9282\n",
      "Epoch 33/100\n",
      "35518/35518 [==============================] - 5s 150us/step - loss: 0.0275 - acc: 0.9309\n",
      "Epoch 34/100\n",
      "35518/35518 [==============================] - 5s 153us/step - loss: 0.0266 - acc: 0.9338\n",
      "Epoch 35/100\n",
      "35518/35518 [==============================] - 5s 151us/step - loss: 0.0257 - acc: 0.9358\n",
      "Epoch 36/100\n",
      "35518/35518 [==============================] - 5s 152us/step - loss: 0.0248 - acc: 0.9384\n",
      "Epoch 37/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.0241 - acc: 0.9405\n",
      "Epoch 38/100\n",
      "35518/35518 [==============================] - 6s 162us/step - loss: 0.0233 - acc: 0.9428\n",
      "Epoch 39/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.0226 - acc: 0.9447\n",
      "Epoch 40/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0221 - acc: 0.9461\n",
      "Epoch 41/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0213 - acc: 0.9484\n",
      "Epoch 42/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.0207 - acc: 0.9503\n",
      "Epoch 43/100\n",
      "35518/35518 [==============================] - 6s 155us/step - loss: 0.0202 - acc: 0.9511\n",
      "Epoch 44/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0198 - acc: 0.9524\n",
      "Epoch 45/100\n",
      "35518/35518 [==============================] - 5s 152us/step - loss: 0.0193 - acc: 0.9542\n",
      "Epoch 46/100\n",
      "35518/35518 [==============================] - 5s 150us/step - loss: 0.0189 - acc: 0.9551\n",
      "Epoch 47/100\n",
      "35518/35518 [==============================] - 5s 150us/step - loss: 0.0183 - acc: 0.9569\n",
      "Epoch 48/100\n",
      "35518/35518 [==============================] - 5s 153us/step - loss: 0.0180 - acc: 0.9577\n",
      "Epoch 49/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0175 - acc: 0.9589\n",
      "Epoch 50/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0175 - acc: 0.9588\n",
      "Epoch 51/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.0169 - acc: 0.9603\n",
      "Epoch 52/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0167 - acc: 0.9610\n",
      "Epoch 53/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0163 - acc: 0.9619\n",
      "Epoch 54/100\n",
      "35518/35518 [==============================] - 5s 153us/step - loss: 0.0161 - acc: 0.9624\n",
      "Epoch 55/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.0159 - acc: 0.9629\n",
      "Epoch 56/100\n",
      "35518/35518 [==============================] - 5s 151us/step - loss: 0.0155 - acc: 0.9642\n",
      "Epoch 57/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0155 - acc: 0.9635\n",
      "Epoch 58/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0151 - acc: 0.9648\n",
      "Epoch 59/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.0149 - acc: 0.9652\n",
      "Epoch 60/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0148 - acc: 0.9656\n",
      "Epoch 61/100\n",
      "35518/35518 [==============================] - 6s 161us/step - loss: 0.0146 - acc: 0.9659\n",
      "Epoch 62/100\n",
      "35518/35518 [==============================] - 7s 187us/step - loss: 0.0145 - acc: 0.9664\n",
      "Epoch 63/100\n",
      "35518/35518 [==============================] - 7s 186us/step - loss: 0.0145 - acc: 0.9665\n",
      "Epoch 64/100\n",
      "35518/35518 [==============================] - 6s 167us/step - loss: 0.0142 - acc: 0.9672\n",
      "Epoch 65/100\n",
      "35518/35518 [==============================] - 6s 159us/step - loss: 0.0141 - acc: 0.9676\n",
      "Epoch 66/100\n",
      "35518/35518 [==============================] - 6s 158us/step - loss: 0.0140 - acc: 0.9678\n",
      "Epoch 67/100\n",
      "35518/35518 [==============================] - 6s 177us/step - loss: 0.0138 - acc: 0.9681\n",
      "Epoch 68/100\n",
      "35518/35518 [==============================] - 7s 183us/step - loss: 0.0137 - acc: 0.9682\n",
      "Epoch 69/100\n",
      "35518/35518 [==============================] - 7s 187us/step - loss: 0.0137 - acc: 0.9685\n",
      "Epoch 70/100\n",
      "35518/35518 [==============================] - 6s 179us/step - loss: 0.0137 - acc: 0.9684\n",
      "Epoch 71/100\n",
      "35518/35518 [==============================] - 6s 160us/step - loss: 0.0136 - acc: 0.9687\n",
      "Epoch 72/100\n",
      "35518/35518 [==============================] - 5s 152us/step - loss: 0.0135 - acc: 0.9688\n",
      "Epoch 73/100\n",
      "35518/35518 [==============================] - 6s 155us/step - loss: 0.0134 - acc: 0.9692\n",
      "Epoch 74/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.0134 - acc: 0.9692\n",
      "Epoch 75/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.0132 - acc: 0.9695\n",
      "Epoch 76/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0131 - acc: 0.9699\n",
      "Epoch 77/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.0132 - acc: 0.9697\n",
      "Epoch 78/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.0130 - acc: 0.9701\n",
      "Epoch 79/100\n",
      "35518/35518 [==============================] - 6s 158us/step - loss: 0.0130 - acc: 0.9702\n",
      "Epoch 80/100\n",
      "35518/35518 [==============================] - 6s 155us/step - loss: 0.0129 - acc: 0.9702\n",
      "Epoch 81/100\n",
      "35518/35518 [==============================] - 5s 154us/step - loss: 0.0129 - acc: 0.9703\n",
      "Epoch 82/100\n",
      "35518/35518 [==============================] - 6s 159us/step - loss: 0.0129 - acc: 0.9703\n",
      "Epoch 83/100\n",
      "35518/35518 [==============================] - 5s 152us/step - loss: 0.0129 - acc: 0.9703\n",
      "Epoch 84/100\n",
      "35518/35518 [==============================] - 5s 151us/step - loss: 0.0129 - acc: 0.9704\n",
      "Epoch 85/100\n",
      "35518/35518 [==============================] - 6s 155us/step - loss: 0.0129 - acc: 0.9704\n",
      "Epoch 86/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.0129 - acc: 0.9704\n",
      "Epoch 87/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0128 - acc: 0.9704\n",
      "Epoch 88/100\n",
      "35518/35518 [==============================] - 6s 158us/step - loss: 0.0128 - acc: 0.9704\n",
      "Epoch 89/100\n",
      "35518/35518 [==============================] - 6s 163us/step - loss: 0.0128 - acc: 0.9704\n",
      "Epoch 90/100\n",
      "35518/35518 [==============================] - 6s 173us/step - loss: 0.0128 - acc: 0.9704\n",
      "Epoch 91/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.0128 - acc: 0.9704\n",
      "Epoch 92/100\n",
      "35518/35518 [==============================] - 6s 167us/step - loss: 0.0128 - acc: 0.9704\n",
      "Epoch 93/100\n",
      "35518/35518 [==============================] - 6s 163us/step - loss: 0.0128 - acc: 0.9704\n",
      "Epoch 94/100\n",
      "35518/35518 [==============================] - 5s 152us/step - loss: 0.0128 - acc: 0.9704\n",
      "Epoch 95/100\n",
      "35518/35518 [==============================] - 6s 159us/step - loss: 0.0128 - acc: 0.9704\n",
      "Epoch 96/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.0128 - acc: 0.9704\n",
      "Epoch 97/100\n",
      "35518/35518 [==============================] - 6s 156us/step - loss: 0.0128 - acc: 0.9705\n",
      "Epoch 98/100\n",
      "35518/35518 [==============================] - 6s 158us/step - loss: 0.0128 - acc: 0.9705\n",
      "Epoch 99/100\n",
      "35518/35518 [==============================] - 6s 162us/step - loss: 0.0128 - acc: 0.9705\n",
      "Epoch 100/100\n",
      "35518/35518 [==============================] - 6s 157us/step - loss: 0.0128 - acc: 0.9705\n",
      "17495/17495 [==============================] - 1s 49us/step\n",
      "TEST: \n",
      "\n",
      "acc: 49.73%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model_8 = Sequential()\n",
    "model_8.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n",
    "model_8.add(Dense(32, input_dim=16, activation='relu'))\n",
    "model_8.add(Dense(16, input_dim=8, activation='relu'))\n",
    "model_8.add(Dense(1, input_dim=8, activation='sigmoid'))\n",
    "# Compile model\n",
    "model_8.compile(loss='logcosh', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_8.fit(X_train, y_train, epochs=100, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model_8.evaluate(X_test, y_test)\n",
    "print('TEST: ')\n",
    "print(\"\\n%s: %.2f%%\" % (model_8.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model_8.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 9: 4 capas, 100 épocas de entrenamiento, pérdida con función *logcosh*, *Stochastic gradient descent*, batch_size=5\n",
    "Advertencia: Tiempo de ejecución superior a 40 minutos en HP Envy 15 (Intel Core I7 2400 Mhz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35518/35518 [==============================] - 20s 565us/step - loss: 0.1204 - acc: 0.5015\n",
      "Epoch 2/100\n",
      "35518/35518 [==============================] - 19s 521us/step - loss: 0.1200 - acc: 0.5145\n",
      "Epoch 3/100\n",
      "35518/35518 [==============================] - 17s 484us/step - loss: 0.1197 - acc: 0.5287\n",
      "Epoch 4/100\n",
      "35518/35518 [==============================] - 16s 464us/step - loss: 0.1194 - acc: 0.5352\n",
      "Epoch 5/100\n",
      "35518/35518 [==============================] - 16s 457us/step - loss: 0.1191 - acc: 0.5428\n",
      "Epoch 6/100\n",
      "35518/35518 [==============================] - 16s 455us/step - loss: 0.1188 - acc: 0.5490\n",
      "Epoch 7/100\n",
      "35518/35518 [==============================] - 17s 465us/step - loss: 0.1184 - acc: 0.5556\n",
      "Epoch 8/100\n",
      "35518/35518 [==============================] - 17s 470us/step - loss: 0.1180 - acc: 0.5616\n",
      "Epoch 9/100\n",
      "35518/35518 [==============================] - 18s 513us/step - loss: 0.1175 - acc: 0.5683\n",
      "Epoch 10/100\n",
      "35518/35518 [==============================] - 29s 827us/step - loss: 0.1168 - acc: 0.5730\n",
      "Epoch 11/100\n",
      "35518/35518 [==============================] - 23s 645us/step - loss: 0.1161 - acc: 0.5826\n",
      "Epoch 12/100\n",
      "35518/35518 [==============================] - 20s 556us/step - loss: 0.1152 - acc: 0.5914\n",
      "Epoch 13/100\n",
      "35518/35518 [==============================] - 22s 612us/step - loss: 0.1140 - acc: 0.6003\n",
      "Epoch 14/100\n",
      "35518/35518 [==============================] - 25s 691us/step - loss: 0.1126 - acc: 0.6106\n",
      "Epoch 15/100\n",
      "35518/35518 [==============================] - 19s 549us/step - loss: 0.1107 - acc: 0.6237\n",
      "Epoch 16/100\n",
      "35518/35518 [==============================] - 19s 538us/step - loss: 0.1084 - acc: 0.6368\n",
      "Epoch 17/100\n",
      "35518/35518 [==============================] - 17s 468us/step - loss: 0.1055 - acc: 0.6520\n",
      "Epoch 18/100\n",
      "35518/35518 [==============================] - 17s 473us/step - loss: 0.1023 - acc: 0.6670\n",
      "Epoch 19/100\n",
      "35518/35518 [==============================] - 19s 521us/step - loss: 0.0985 - acc: 0.6863\n",
      "Epoch 20/100\n",
      "35518/35518 [==============================] - 19s 537us/step - loss: 0.0940 - acc: 0.7067\n",
      "Epoch 21/100\n",
      "35518/35518 [==============================] - 16s 455us/step - loss: 0.0890 - acc: 0.7245\n",
      "Epoch 22/100\n",
      "35518/35518 [==============================] - 16s 454us/step - loss: 0.0840 - acc: 0.7449\n",
      "Epoch 23/100\n",
      "35518/35518 [==============================] - 16s 459us/step - loss: 0.0782 - acc: 0.7705\n",
      "Epoch 24/100\n",
      "35518/35518 [==============================] - 16s 446us/step - loss: 0.0723 - acc: 0.7923\n",
      "Epoch 25/100\n",
      "35518/35518 [==============================] - 16s 451us/step - loss: 0.0661 - acc: 0.8131\n",
      "Epoch 26/100\n",
      "35518/35518 [==============================] - 16s 458us/step - loss: 0.0601 - acc: 0.8339\n",
      "Epoch 27/100\n",
      "35518/35518 [==============================] - 17s 486us/step - loss: 0.0536 - acc: 0.8566\n",
      "Epoch 28/100\n",
      "35518/35518 [==============================] - 18s 504us/step - loss: 0.0478 - acc: 0.8738\n",
      "Epoch 29/100\n",
      "35518/35518 [==============================] - 17s 469us/step - loss: 0.0418 - acc: 0.8946\n",
      "Epoch 30/100\n",
      "35518/35518 [==============================] - 17s 465us/step - loss: 0.0362 - acc: 0.9122\n",
      "Epoch 31/100\n",
      "35518/35518 [==============================] - 17s 478us/step - loss: 0.0312 - acc: 0.9259\n",
      "Epoch 32/100\n",
      "35518/35518 [==============================] - 18s 493us/step - loss: 0.0259 - acc: 0.9418\n",
      "Epoch 33/100\n",
      "35518/35518 [==============================] - 17s 490us/step - loss: 0.0219 - acc: 0.9542\n",
      "Epoch 34/100\n",
      "35518/35518 [==============================] - 18s 509us/step - loss: 0.0178 - acc: 0.9643\n",
      "Epoch 35/100\n",
      "35518/35518 [==============================] - 22s 632us/step - loss: 0.0141 - acc: 0.9747\n",
      "Epoch 36/100\n",
      "35518/35518 [==============================] - 17s 468us/step - loss: 0.0111 - acc: 0.9821\n",
      "Epoch 37/100\n",
      "35518/35518 [==============================] - 16s 459us/step - loss: 0.0084 - acc: 0.9883\n",
      "Epoch 38/100\n",
      "35518/35518 [==============================] - 17s 473us/step - loss: 0.0062 - acc: 0.9915\n",
      "Epoch 39/100\n",
      "35518/35518 [==============================] - 21s 580us/step - loss: 0.0047 - acc: 0.9930\n",
      "Epoch 40/100\n",
      "35518/35518 [==============================] - 32s 908us/step - loss: 0.0039 - acc: 0.9934\n",
      "Epoch 41/100\n",
      "35518/35518 [==============================] - 25s 690us/step - loss: 0.0035 - acc: 0.9938\n",
      "Epoch 42/100\n",
      "35518/35518 [==============================] - 22s 624us/step - loss: 0.0032 - acc: 0.9940\n",
      "Epoch 43/100\n",
      "35518/35518 [==============================] - 18s 511us/step - loss: 0.0030 - acc: 0.9942\n",
      "Epoch 44/100\n",
      "35518/35518 [==============================] - 16s 462us/step - loss: 0.0029 - acc: 0.9944\n",
      "Epoch 45/100\n",
      "35518/35518 [==============================] - 16s 458us/step - loss: 0.0028 - acc: 0.9945\n",
      "Epoch 46/100\n",
      "35518/35518 [==============================] - 16s 462us/step - loss: 0.0028 - acc: 0.9945\n",
      "Epoch 47/100\n",
      "35518/35518 [==============================] - 16s 461us/step - loss: 0.0027 - acc: 0.9946\n",
      "Epoch 48/100\n",
      "35518/35518 [==============================] - 16s 458us/step - loss: 0.0026 - acc: 0.9947\n",
      "Epoch 49/100\n",
      "35518/35518 [==============================] - 16s 460us/step - loss: 0.0026 - acc: 0.9947\n",
      "Epoch 50/100\n",
      "35518/35518 [==============================] - 16s 456us/step - loss: 0.0025 - acc: 0.9949\n",
      "Epoch 51/100\n",
      "35518/35518 [==============================] - 16s 459us/step - loss: 0.0025 - acc: 0.9949\n",
      "Epoch 52/100\n",
      "35518/35518 [==============================] - 18s 518us/step - loss: 0.0024 - acc: 0.9949\n",
      "Epoch 53/100\n",
      "35518/35518 [==============================] - 19s 545us/step - loss: 0.0024 - acc: 0.9950\n",
      "Epoch 54/100\n",
      "35518/35518 [==============================] - 17s 469us/step - loss: 0.0024 - acc: 0.9951\n",
      "Epoch 55/100\n",
      "35518/35518 [==============================] - 17s 472us/step - loss: 0.0023 - acc: 0.9952\n",
      "Epoch 56/100\n",
      "35518/35518 [==============================] - 17s 473us/step - loss: 0.0023 - acc: 0.9952\n",
      "Epoch 57/100\n",
      "35518/35518 [==============================] - 16s 459us/step - loss: 0.0022 - acc: 0.9953\n",
      "Epoch 58/100\n",
      "35518/35518 [==============================] - 17s 469us/step - loss: 0.0022 - acc: 0.9953\n",
      "Epoch 59/100\n",
      "35518/35518 [==============================] - 17s 481us/step - loss: 0.0022 - acc: 0.9954\n",
      "Epoch 60/100\n",
      "35518/35518 [==============================] - 18s 502us/step - loss: 0.0022 - acc: 0.9954\n",
      "Epoch 61/100\n",
      "35518/35518 [==============================] - 16s 462us/step - loss: 0.0021 - acc: 0.9954\n",
      "Epoch 62/100\n",
      "35518/35518 [==============================] - 17s 470us/step - loss: 0.0021 - acc: 0.9955\n",
      "Epoch 63/100\n",
      "35518/35518 [==============================] - 16s 461us/step - loss: 0.0021 - acc: 0.9955\n",
      "Epoch 64/100\n",
      "35518/35518 [==============================] - 16s 463us/step - loss: 0.0021 - acc: 0.9956\n",
      "Epoch 65/100\n",
      "35518/35518 [==============================] - 17s 465us/step - loss: 0.0021 - acc: 0.9956\n",
      "Epoch 66/100\n",
      "35518/35518 [==============================] - 17s 469us/step - loss: 0.0021 - acc: 0.9956\n",
      "Epoch 67/100\n",
      "35518/35518 [==============================] - 18s 510us/step - loss: 0.0020 - acc: 0.9956\n",
      "Epoch 68/100\n",
      "35518/35518 [==============================] - 18s 519us/step - loss: 0.0020 - acc: 0.9956\n",
      "Epoch 69/100\n",
      "35518/35518 [==============================] - 19s 525us/step - loss: 0.0020 - acc: 0.9956\n",
      "Epoch 70/100\n",
      "35518/35518 [==============================] - 17s 485us/step - loss: 0.0020 - acc: 0.9956\n",
      "Epoch 71/100\n",
      "35518/35518 [==============================] - 17s 469us/step - loss: 0.0020 - acc: 0.9956\n",
      "Epoch 72/100\n",
      "35518/35518 [==============================] - 16s 447us/step - loss: 0.0020 - acc: 0.9957\n",
      "Epoch 73/100\n",
      "35518/35518 [==============================] - 16s 451us/step - loss: 0.0020 - acc: 0.9957\n",
      "Epoch 74/100\n",
      "35518/35518 [==============================] - 16s 453us/step - loss: 0.0020 - acc: 0.9957\n",
      "Epoch 75/100\n",
      "35518/35518 [==============================] - 17s 479us/step - loss: 0.0019 - acc: 0.9957\n",
      "Epoch 76/100\n",
      "35518/35518 [==============================] - 17s 467us/step - loss: 0.0019 - acc: 0.9957\n",
      "Epoch 77/100\n",
      "35518/35518 [==============================] - 16s 446us/step - loss: 0.0019 - acc: 0.9957\n",
      "Epoch 78/100\n",
      "35518/35518 [==============================] - 16s 455us/step - loss: 0.0019 - acc: 0.9957\n",
      "Epoch 79/100\n",
      "35518/35518 [==============================] - 16s 449us/step - loss: 0.0019 - acc: 0.9957\n",
      "Epoch 80/100\n",
      "35518/35518 [==============================] - 16s 457us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 81/100\n",
      "35518/35518 [==============================] - 16s 450us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 82/100\n",
      "35518/35518 [==============================] - 16s 452us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 83/100\n",
      "35518/35518 [==============================] - 16s 450us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 84/100\n",
      "35518/35518 [==============================] - 16s 450us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 85/100\n",
      "35518/35518 [==============================] - 17s 492us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 86/100\n",
      "35518/35518 [==============================] - 19s 542us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 87/100\n",
      "35518/35518 [==============================] - 17s 489us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 88/100\n",
      "35518/35518 [==============================] - 17s 466us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 89/100\n",
      "35518/35518 [==============================] - 16s 457us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 90/100\n",
      "35518/35518 [==============================] - 16s 453us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 91/100\n",
      "35518/35518 [==============================] - 16s 455us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 92/100\n",
      "35518/35518 [==============================] - 16s 461us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 93/100\n",
      "35518/35518 [==============================] - 17s 465us/step - loss: 0.0019 - acc: 0.9958\n",
      "Epoch 94/100\n",
      "35518/35518 [==============================] - 16s 461us/step - loss: 0.0019 - acc: 0.9959\n",
      "Epoch 95/100\n",
      "35518/35518 [==============================] - 17s 473us/step - loss: 0.0019 - acc: 0.9959\n",
      "Epoch 96/100\n",
      "35518/35518 [==============================] - 16s 459us/step - loss: 0.0019 - acc: 0.9959\n",
      "Epoch 97/100\n",
      "35518/35518 [==============================] - 16s 463us/step - loss: 0.0019 - acc: 0.9959\n",
      "Epoch 98/100\n",
      "35518/35518 [==============================] - 16s 456us/step - loss: 0.0018 - acc: 0.9959\n",
      "Epoch 99/100\n",
      "35518/35518 [==============================] - 17s 473us/step - loss: 0.0018 - acc: 0.9959\n",
      "Epoch 100/100\n",
      "35518/35518 [==============================] - 17s 479us/step - loss: 0.0018 - acc: 0.9959\n",
      "17495/17495 [==============================] - 1s 55us/step\n",
      "TEST: \n",
      "\n",
      "acc: 50.39%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model_9 = Sequential()\n",
    "model_9.add(Dense(300, input_dim=X.shape[1], activation='relu'))\n",
    "model_9.add(Dense(200, input_dim=16, activation='relu'))\n",
    "model_9.add(Dense(100, input_dim=8, activation='relu'))\n",
    "model_9.add(Dense(1, input_dim=8, activation='sigmoid'))\n",
    "# Compile model\n",
    "model_9.compile(loss='logcosh', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_9.fit(X_train, y_train, epochs=100, batch_size=5)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model_9.evaluate(X_test, y_test)\n",
    "print('TEST: ')\n",
    "print(\"\\n%s: %.2f%%\" % (model_9.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model_9.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 10: 4 capas, 100 épocas de entrenamiento, pérdida con función *mean_squared_error*, *Stochastic gradient descent*, batch_size=15, softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10 = Sequential()\n",
    "model_10.add(Dense(16, input_dim=X.shape[1], activation='relu'))\n",
    "model_10.add(Dense(8, input_dim=16, activation='relu'))\n",
    "model_10.add(Dense(8, input_dim=8, activation='relu'))\n",
    "model_10.add(Dense(1, input_dim=8, activation='softmax'))\n",
    "# Compile model\n",
    "model_10.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_10.fit(X_train, y_train, epochs=100, batch_size=15)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model_10.evaluate(X_test, y_test)\n",
    "print('TEST: ')\n",
    "print(\"\\n%s: %.2f%%\" % (model_10.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model_10.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "Comentarios generales de los resultados obtenidos podrán encontrarse en el informe de la Entrega 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias bibliográficas\n",
    "- Develop Your First Neural Network in Python With Keras Step-By-Step. Machine Learning Mastery [online]. Fecha de consulta: 28 de octubre de 2018. Disponible en (URL): https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "- Keros.io [online]. Fecha de consulta: 28 de octubre de 2018. Disponible en (URL):https://keras.io/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
